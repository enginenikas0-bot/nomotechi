import feedparser
import json
import os
import datetime
import time

# Î‘ÏÏ‡ÎµÎ¯Î¿ Î²Î¬ÏƒÎ·Ï‚ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½
DB_FILE = 'laws_db.json'

# Î›Î¯ÏƒÏ„Î± Î¼Îµ Ï€ÏÎ±Î³Î¼Î±Ï„Î¹ÎºÎ­Ï‚ Ï€Î·Î³Î­Ï‚ RSS (Î•Î¹Î´Î®ÏƒÎµÎ¹Ï‚ Î³Î¹Î± ÎœÎ·Ï‡Î±Î½Î¹ÎºÎ¿ÏÏ‚ & ÎÎ¿Î¼Î¹ÎºÎ¬)
RSS_FEEDS = {
    "Taxheaven": "https://www.taxheaven.gr/rss",
    "Lawspot": "https://www.lawspot.gr/nomika-nea/feed",
    "B2Green": "https://news.b2green.gr/feed"
}

def load_data():
    """Î¦Î¿ÏÏ„ÏÎ½ÎµÎ¹ Ï„Î·Î½ Ï…Ï€Î¬ÏÏ‡Î¿Ï…ÏƒÎ± Î²Î¬ÏƒÎ·."""
    if not os.path.exists(DB_FILE):
        return []
    with open(DB_FILE, 'r', encoding='utf-8') as f:
        try:
            return json.load(f)
        except json.JSONDecodeError:
            return []

def save_data(data):
    """Î‘Ï€Î¿Î¸Î·ÎºÎµÏÎµÎ¹ Ï„Î· Î²Î¬ÏƒÎ·."""
    with open(DB_FILE, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=4)

def run_bot():
    print("ğŸ¤– Î¤Î¿ ÏÎ¿Î¼Ï€Î¿Ï„Î¬ÎºÎ¹ Î¾ÎµÎºÎ¯Î½Î·ÏƒÎµ ÎºÎ±Î¹ ÏƒÎºÎ±Î½Î¬ÏÎµÎ¹ Ï„Î¿ Î¯Î½Ï„ÎµÏÎ½ÎµÏ„...")
    current_data = load_data()
    new_entries_count = 0

    # Î£ÎºÎ±Î½Î¬ÏÎ¹ÏƒÎ¼Î± ÎºÎ¬Î¸Îµ Ï€Î·Î³Î®Ï‚
    for source_name, url in RSS_FEEDS.items():
        print(f"ğŸ“¡ ÎˆÎ»ÎµÎ³Ï‡Î¿Ï‚ Ï€Î·Î³Î®Ï‚: {source_name}...")
        try:
            feed = feedparser.parse(url)
            
            # ÎˆÎ»ÎµÎ³Ï‡Î¿Ï‚ Î±Î½ Ï„Î¿ feed ÎºÎ±Ï„Î­Î²Î·ÎºÎµ ÏƒÏ‰ÏƒÏ„Î¬
            if feed.bozo:
                print(f"âš ï¸ Î ÏÏŒÎ²Î»Î·Î¼Î± Î¼Îµ Ï„Î¿ feed Ï„Î¿Ï… {source_name}")
                continue

            # Î Î±Î¯ÏÎ½Î¿Ï…Î¼Îµ Ï„Î± 5 Ï€Î¹Î¿ Ï€ÏÏŒÏƒÏ†Î±Ï„Î± Î¬ÏÎ¸ÏÎ± Î±Ï€ÏŒ ÎºÎ¬Î¸Îµ Ï€Î·Î³Î®
            for entry in feed.entries[:5]:
                title = entry.title
                link = entry.link
                # ÎšÎ±Î¸Î±ÏÎ¹ÏƒÎ¼ÏŒÏ‚ Î·Î¼ÎµÏÎ¿Î¼Î·Î½Î¯Î±Ï‚ (Î±Î½ Ï…Ï€Î¬ÏÏ‡ÎµÎ¹)
                published = entry.get('published', datetime.datetime.now().strftime("%Y-%m-%d"))
                
                # ÎˆÎ»ÎµÎ³Ï‡Î¿Ï‚ Î±Î½ Ï…Ï€Î¬ÏÏ‡ÎµÎ¹ Î®Î´Î· ÏƒÏ„Î· Î²Î¬ÏƒÎ· Î¼Î±Ï‚ (Î¼Îµ Î²Î¬ÏƒÎ· Ï„Î¿ Link)
                if any(d.get('link') == link for d in current_data):
                    continue  # Î¤Î¿ Î­Ï‡Î¿Ï…Î¼Îµ Î®Î´Î·, Ï€ÏÎ¿Ï‡Ï‰ÏÎ¬Î¼Îµ
                
                # Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± Î½Î­Î±Ï‚ ÎµÎ³Î³ÏÎ±Ï†Î®Ï‚
                new_article = {
                    "id": len(current_data) + 1 + new_entries_count,
                    "law": source_name,  # Î Î·Î³Î® Î±Î½Ï„Î¯ Î³Î¹Î± ÎÏŒÎ¼Î¿
                    "article": "RSS Feed",
                    "category": "Î•Ï€Î¹ÎºÎ±Î¹ÏÏŒÏ„Î·Ï„Î±",
                    "title": title,
                    "content": f"{entry.summary[:200]}... [Î”Î¹Î±Î²Î¬ÏƒÏ„Îµ Ï€ÎµÏÎ¹ÏƒÏƒÏŒÏ„ÎµÏÎ±]({link})",
                    "link": link, # Î‘Ï€Î¿Î¸Î·ÎºÎµÏÎ¿Ï…Î¼Îµ ÎºÎ±Î¹ Ï„Î¿ link
                    "last_update": published,
                    "status": "ÎÎ•ÎŸ"
                }
                
                current_data.append(new_article)
                new_entries_count += 1
                print(f"   âœ… Î’ÏÎ­Î¸Î·ÎºÎµ Î½Î­Î¿ Î¬ÏÎ¸ÏÎ¿: {title[:50]}...")

        except Exception as e:
            print(f"âŒ Î£Ï†Î¬Î»Î¼Î± ÎºÎ±Ï„Î¬ Ï„Î· ÏƒÏÎ½Î´ÎµÏƒÎ· Î¼Îµ {source_name}: {e}")

    if new_entries_count > 0:
        save_data(current_data)
        print(f"\nğŸ‰ ÎŸÎ»Î¿ÎºÎ»Î·ÏÏÎ¸Î·ÎºÎµ! Î ÏÎ¿ÏƒÏ„Î­Î¸Î·ÎºÎ±Î½ {new_entries_count} Î½Î­Î± Î¸Î­Î¼Î±Ï„Î± ÏƒÏ„Î· Î²Î¬ÏƒÎ·.")
    else:
        print("\nğŸ’¤ Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎ±Î½ Î½Î­Î± Î¸Î­Î¼Î±Ï„Î±. Î— Î²Î¬ÏƒÎ· ÎµÎ¯Î½Î±Î¹ ÎµÎ½Î·Î¼ÎµÏÏ‰Î¼Î­Î½Î·.")

if __name__ == "__main__":
    run_bot()