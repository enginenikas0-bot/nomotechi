import os
import json
import gspread
import feedparser
from datetime import datetime

# --- 1. ÎŸÎ›Î•Î£ ÎŸÎ™ Î Î—Î“Î•Î£ Î•Î™Î”Î—Î£Î•Î©Î (RSS) ---
RSS_FEEDS = {
    "ğŸ›ï¸ Î¤Î•Î•": "https://web.tee.gr/feed/",
    "ğŸ—ï¸ Ypodomes": "https://ypodomes.com/feed/",
    "ğŸŒ¿ B2Green": "https://news.b2green.gr/feed",
    "ğŸ’¼ Taxheaven": "https://www.taxheaven.gr/rss",
    "âš–ï¸ Lawspot": "https://www.lawspot.gr/nomika-nea/feed",
    "âš¡ EnergyPress": "https://energypress.gr/feed",
    "ğŸšœ PEDMEDE (Î•ÏÎ³Î¿Î»Î®Ï€Ï„ÎµÏ‚)": "https://www.pedmede.gr/feed/",
    "ğŸ‘· Michanikos": "https://www.michanikos-online.gr/feed/",
    "â™»ï¸ GreenAgenda": "https://greenagenda.gr/feed/",
    "ğŸ“ Archetypes": "https://www.archetypes.gr/feed/"
}

# --- 2. Î•ÎÎ¥Î ÎÎ— ÎšÎ‘Î¤Î—Î“ÎŸÎ¡Î™ÎŸÎ ÎŸÎ™Î—Î£Î— ---
def guess_category(text):
    text = text.lower()
    
    # Î Î¿Î»ÎµÎ¿Î´Î¿Î¼Î¯Î± & Î”ÏŒÎ¼Î·ÏƒÎ·
    if any(x in text for x in ['Î±Ï…Î¸Î±Î¯ÏÎµÏ„Î±', '4495', 'Ï€Î¿Î»ÎµÎ¿Î´Î¿Î¼', 'Î´ÏŒÎ¼Î·ÏƒÎ·', 'ÎºÏ„Î¹ÏÎ¹Î¿Î´Î¿Î¼', 'Î±Î´ÎµÎ¹ÎµÏ‚', 'Î½.Î¿.Îº.', 'Î½Î¿Îº', 'Î¿Î¹ÎºÎ¿Î´Î¿Î¼', 'ÎºÎ±Ï„Î±ÏƒÎºÎµÏ…', 'real estate', 'ÎºÏ„Î·Î¼Î±Ï„Î¿Î»ÏŒÎ³Î¹Î¿', 'Î´Î±ÏƒÎ¹Îº', 'Î±ÏÏ‡Î¹Ï„ÎµÎºÏ„Î¿Î½', 'design']):
        return "ğŸ“ Î Î¿Î»ÎµÎ¿Î´Î¿Î¼Î¯Î± & Î”ÏŒÎ¼Î·ÏƒÎ·"
    
    # Î•Î½Î­ÏÎ³ÎµÎ¹Î± & Î ÎµÏÎ¹Î²Î¬Î»Î»Î¿Î½
    elif any(x in text for x in ['ÎµÎ¾Î¿Î¹ÎºÎ¿Î½Î¿Î¼Ï', 'ÎµÎ½Î­ÏÎ³ÎµÎ¹Î±', 'Ï†Ï‰Ï„Î¿Î²Î¿Î»Ï„Î±ÏŠÎºÎ¬', 'Î±Î½Î±ÎºÏÎºÎ»Ï‰ÏƒÎ·', 'Ï€ÎµÏÎ¹Î²Î¬Î»Î»Î¿Î½', 'ÎµÎ½ÎµÏÎ³ÎµÎ¹Î±Îº', 'green', 'Î±Ï€Îµ', 'ÏÎ±Îµ', 'energy', 'Î±Ï€ÏŒÎ²Î»Î·Ï„Î±', 'ÎºÏ…ÎºÎ»Î¹ÎºÎ®', 'ÎºÎ»Î¹Î¼Î±Ï„Î¹Îº', 'Ï…Î´ÏÎ¿Î³ÏŒÎ½Î¿']):
        return "ğŸŒ± Î•Î½Î­ÏÎ³ÎµÎ¹Î± & Î ÎµÏÎ¹Î²Î¬Î»Î»Î¿Î½"
    
    # Î¦Î¿ÏÎ¿Î»Î¿Î³Î¹ÎºÎ¬ & Î‘ÏƒÏ†Î±Î»Î¹ÏƒÏ„Î¹ÎºÎ¬
    elif any(x in text for x in ['Ï†Î¿ÏÎ¿Î»Î¿Î³', 'Î±Î±Î´Îµ', 'mydata', 'ÎµÏ†Î¿ÏÎ¯Î±', 'ÎµÎ¹ÏƒÏ†Î¿ÏÎ­Ï‚', 'Ï†Ï€Î±', 'Î¼Î¹ÏƒÎ¸Î¿Î´Î¿ÏƒÎ¯Î±', 'Î»Î¿Î³Î¹ÏƒÏ„Î¹Îº', 'Î¿Î¹ÎºÎ¿Î½Î¿Î¼Î¹Îº', 'Ï„ÏƒÎ¼ÎµÎ´Îµ', 'ÎµÏ†ÎºÎ±', 'ÎµÏ€Î¹Î´ÏŒÏ„Î·ÏƒÎ·', 'Î±Î½Î±Ï€Ï„Ï…Î¾Î¹Î±Îº']):
        return "ğŸ’¼ Î¦Î¿ÏÎ¿Î»Î¿Î³Î¹ÎºÎ¬ & Î‘ÏƒÏ†Î±Î»Î¹ÏƒÏ„Î¹ÎºÎ¬"
    
    # Î”Î·Î¼ÏŒÏƒÎ¹Î± ÎˆÏÎ³Î± & Î•Î£Î Î‘
    elif any(x in text for x in ['Î´Î¹Î±Î³Ï‰Î½Î¹ÏƒÎ¼', 'Î´Î·Î¼ÏŒÏƒÎ¹Î± Î­ÏÎ³Î±', 'Î¼ÎµÎ»Î­Ï„ÎµÏ‚', 'ÏƒÏÎ¼Î²Î±ÏƒÎ·', 'Î±Î½Î¬Î¸ÎµÏƒÎ·', 'ÎµÏƒÏ€Î±', 'Ï…Ï€Î¿Î´Î¿Î¼Î­Ï‚', 'Î¼ÎµÏ„ÏÏŒ', 'Î¿Î´Î¹ÎºÏŒÏ‚', 'Ï€Î±ÏÎ±Ï‡ÏÏÎ·ÏƒÎ·', 'Ï€ÎµÎ´Î¼ÎµÎ´Îµ', 'Î´Î¹Î±ÎºÎ®ÏÏ…Î¾Î·', 'Î¼ÎµÎ¹Î¿Î´Î¿Ï„', 'ÎµÏÎ³Î¿Î»Î·Ï€']):
        return "âœ’ï¸ Î”Î·Î¼ÏŒÏƒÎ¹Î± ÎˆÏÎ³Î± & Î•Î£Î Î‘"
    
    # Î˜ÎµÏƒÎ¼Î¹ÎºÎ¬ Î¤Î•Î• & Î•Ï€Î±Î³Î³ÎµÎ»Î¼Î±Ï„Î¹ÎºÎ¬
    elif any(x in text for x in ['Ï„ÎµÎµ', 'Î¼Î·Ï‡Î±Î½Î¹Îº', 'ÎµÏ€Î¹Î¼ÎµÎ»Î·Ï„Î®ÏÎ¹Î¿', 'ÎµÎºÎ»Î¿Î³Î­Ï‚', 'Ï€ÎµÎ¹Î¸Î±ÏÏ‡Î¹Îº', 'ÏƒÎµÎ¼Î¹Î½Î¬ÏÎ¹', 'Î·Î¼ÎµÏÎ¯Î´Î±', 'ÏƒÏ…Î½Î­Î´ÏÎ¹Î¿']):
        return "ğŸ›ï¸ Î˜ÎµÏƒÎ¼Î¹ÎºÎ¬ Î¤Î•Î• & Î•Ï€Î¬Î³Î³ÎµÎ»Î¼Î±"
        
    else:
        return "ğŸ“¢ Î“ÎµÎ½Î¹ÎºÎ® Î•Î½Î·Î¼Î­ÏÏ‰ÏƒÎ·"

# --- 3. ÎšÎ¥Î¡Î™Î‘ Î›Î•Î™Î¤ÎŸÎ¥Î¡Î“Î™Î‘ Î¡ÎŸÎœÎ ÎŸÎ¤ ---
def run():
    print("ğŸ¤– Î¤Î¿ ÏÎ¿Î¼Ï€Î¿Ï„Î¬ÎºÎ¹ Î¾ÎµÎºÎ¯Î½Î·ÏƒÎµ ÏƒÎ¬ÏÏ‰ÏƒÎ· ÏƒÎµ 10 Ï€Î·Î³Î­Ï‚...")
    
    # Î‘Î½Î¬ÎºÏ„Î·ÏƒÎ· ÎºÏ‰Î´Î¹ÎºÏÎ½ Î±Ï€ÏŒ Ï„Î± Secrets Ï„Î¿Ï… GitHub
    json_creds = os.environ.get("GCP_CREDENTIALS")
    if not json_creds:
        print("âŒ Î£Ï†Î¬Î»Î¼Î±: Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎ±Î½ ÎºÏ‰Î´Î¹ÎºÎ¿Î¯ (GCP_CREDENTIALS).")
        return

    try:
        creds_dict = json.loads(json_creds)
        gc = gspread.service_account_from_dict(creds_dict)
        sh = gc.open("laws_database") # Î¤Î¿ ÏŒÎ½Î¿Î¼Î± Ï„Î¿Ï… Sheet ÏƒÎ¿Ï…
        sheet = sh.sheet1
    except Exception as e:
        print(f"âŒ Î£Ï†Î¬Î»Î¼Î± ÏƒÏÎ½Î´ÎµÏƒÎ·Ï‚ Î¼Îµ Google Sheets: {e}")
        return

    # Î‘Î½Î¬Î³Î½Ï‰ÏƒÎ· Ï…Ï€Î±ÏÏ‡ÏŒÎ½Ï„Ï‰Î½ Î³Î¹Î± Î½Î± Î¼Î·Î½ Î­Ï‡Î¿Ï…Î¼Îµ Î´Î¹Ï€Î»ÏŒÏ„Ï…Ï€Î±
    try:
        existing_data = sheet.get_all_records()
        existing_links = [row['link'] for row in existing_data]
    except:
        existing_data = []
        existing_links = []
        
    new_items_count = 0

    # Î£Î¬ÏÏ‰ÏƒÎ· ÎºÎ¬Î¸Îµ Ï€Î·Î³Î®Ï‚
    for source_name, url in RSS_FEEDS.items():
        print(f"ğŸ“¡ ÎˆÎ»ÎµÎ³Ï‡Î¿Ï‚: {source_name}...")
        try:
            feed = feedparser.parse(url)
            # Î Î±Î¯ÏÎ½Î¿Ï…Î¼Îµ Ï„Î± 3 Ï€Î¹Î¿ Ï€ÏÏŒÏƒÏ†Î±Ï„Î± Î±Ï€ÏŒ ÎºÎ¬Î¸Îµ Ï€Î·Î³Î®
            for entry in feed.entries[:3]:
                if entry.link not in existing_links:
                    
                    category = guess_category(entry.title + " " + entry.summary)
                    
                    new_row = [
                        len(existing_data) + new_items_count + 1,
                        source_name,
                        entry.title,
                        entry.summary[:200] + "...",
                        entry.link,
                        datetime.now().strftime("%Y-%m-%d"),
                        category
                    ]
                    
                    sheet.append_row(new_row)
                    new_items_count += 1
                    existing_links.append(entry.link)
                    print(f"   âœ… ÎÎ­Î¿: {entry.title[:40]}...")
                    
        except Exception as e:
            print(f"   âš ï¸ Î ÏÏŒÎ²Î»Î·Î¼Î± Î¼Îµ Ï„Î¿ feed {source_name}: {e}")

    print(f"ğŸ ÎŸÎ»Î¿ÎºÎ»Î·ÏÏÎ¸Î·ÎºÎµ! Î ÏÎ¿ÏƒÏ„Î­Î¸Î·ÎºÎ±Î½ {new_items_count} Î½Î­Î± Î¸Î­Î¼Î±Ï„Î±.")

if __name__ == "__main__":
    run()

