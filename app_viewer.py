import streamlit as st
import pandas as pd
import gspread
import feedparser
from datetime import datetime
import time

# --- 1. RYZMISEIS SELIDAS (PROFESSIONAL UI) ---
st.set_page_config(
    page_title="NomoTechi | Î¤Î¿ Portal Ï„Î¿Ï… ÎœÎ·Ï‡Î±Î½Î¹ÎºÎ¿Ï",
    page_icon="ğŸ›ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS Î³Î¹Î± Ï€Î¹Î¿ "ÎµÏ€Î±Î³Î³ÎµÎ»Î¼Î±Ï„Î¹ÎºÏŒ" look
st.markdown("""
<style>
    .main-header {font-size: 2.5rem; color: #1E3A8A; text-align: center; font-weight: bold;}
    .sub-header {font-size: 1.2rem; color: #4B5563; text-align: center; margin-bottom: 2rem;}
    .card {background-color: #f9f9f9; padding: 20px; border-radius: 10px; border: 1px solid #e5e7eb; margin-bottom: 10px;}
    .source-tag {font-size: 0.8rem; background-color: #E0F2FE; color: #0369A1; padding: 2px 8px; border-radius: 4px;}
    .cat-tag {font-weight: bold; color: #333;}
</style>
""", unsafe_allow_html=True)

# --- 2. SYNDESH ME VASI ---
def get_db_connection():
    try:
        credentials_dict = st.secrets["gcp_service_account"]
        gc = gspread.service_account_from_dict(credentials_dict)
        sh = gc.open("laws_database")
        return sh.sheet1
    except Exception as e:
        st.error(f"âš ï¸ Î£Ï†Î¬Î»Î¼Î± ÏƒÏÎ½Î´ÎµÏƒÎ·Ï‚ Î¼Îµ Ï„Î· Î’Î¬ÏƒÎ·: {e}")
        return None

def load_data():
    sheet = get_db_connection()
    if sheet:
        try:
            return sheet.get_all_records()
        except:
            return []
    return []

# --- 3. LOGIKI ENIMEROSIS (GIA TO ADMIN BUTTON) ---
# Î‘Î½Ï„Î¹Î³ÏÎ¬Ï†Î¿Ï…Î¼Îµ Ï„Î· Î»Î¿Î³Î¹ÎºÎ® ÎºÎ±Î¹ ÎµÎ´Ï Î³Î¹Î± Î½Î± Î´Î¿Ï…Î»ÎµÏÎµÎ¹ Ï„Î¿ manual ÎºÎ¿Ï…Î¼Ï€Î¯
RSS_FEEDS = {
    "ğŸ›ï¸ Î¤Î•Î•": "https://web.tee.gr/feed/",
    "ğŸ—ï¸ Ypodomes": "https://ypodomes.com/feed/",
    "ğŸŒ¿ B2Green": "https://news.b2green.gr/feed",
    "ğŸ’¼ Taxheaven": "https://www.taxheaven.gr/rss",
    "âš–ï¸ Lawspot": "https://www.lawspot.gr/nomika-nea/feed",
    "âš¡ EnergyPress": "https://energypress.gr/feed",
    "ğŸšœ PEDMEDE": "https://www.pedmede.gr/feed/",
    "ğŸ‘· Michanikos": "https://www.michanikos-online.gr/feed/",
    "â™»ï¸ GreenAgenda": "https://greenagenda.gr/feed/",
    "ğŸ“ Archetypes": "https://www.archetypes.gr/feed/"
}

def guess_category(text):
    text = text.lower()
    if any(x in text for x in ['Î±Ï…Î¸Î±Î¯ÏÎµÏ„Î±', '4495', 'Ï€Î¿Î»ÎµÎ¿Î´Î¿Î¼', 'Î´ÏŒÎ¼Î·ÏƒÎ·', 'ÎºÏ„Î¹ÏÎ¹Î¿Î´Î¿Î¼', 'Î±Î´ÎµÎ¹ÎµÏ‚', 'Î½.Î¿.Îº.', 'Î½Î¿Îº', 'Î¿Î¹ÎºÎ¿Î´Î¿Î¼', 'ÎºÎ±Ï„Î±ÏƒÎºÎµÏ…', 'real estate', 'ÎºÏ„Î·Î¼Î±Ï„Î¿Î»ÏŒÎ³Î¹Î¿', 'Î´Î±ÏƒÎ¹Îº']):
        return "ğŸ“ Î Î¿Î»ÎµÎ¿Î´Î¿Î¼Î¯Î± & Î”ÏŒÎ¼Î·ÏƒÎ·"
    elif any(x in text for x in ['ÎµÎ¾Î¿Î¹ÎºÎ¿Î½Î¿Î¼Ï', 'ÎµÎ½Î­ÏÎ³ÎµÎ¹Î±', 'Ï†Ï‰Ï„Î¿Î²Î¿Î»Ï„Î±ÏŠÎºÎ¬', 'Î±Î½Î±ÎºÏÎºÎ»Ï‰ÏƒÎ·', 'Ï€ÎµÏÎ¹Î²Î¬Î»Î»Î¿Î½', 'ÎµÎ½ÎµÏÎ³ÎµÎ¹Î±Îº', 'green', 'Î±Ï€Îµ', 'ÏÎ±Îµ', 'Î±Ï€ÏŒÎ²Î»Î·Ï„Î±']):
        return "ğŸŒ± Î•Î½Î­ÏÎ³ÎµÎ¹Î± & Î ÎµÏÎ¹Î²Î¬Î»Î»Î¿Î½"
    elif any(x in text for x in ['Ï†Î¿ÏÎ¿Î»Î¿Î³', 'Î±Î±Î´Îµ', 'mydata', 'ÎµÏ†Î¿ÏÎ¯Î±', 'ÎµÎ¹ÏƒÏ†Î¿ÏÎ­Ï‚', 'Ï†Ï€Î±', 'Î¼Î¹ÏƒÎ¸Î¿Î´Î¿ÏƒÎ¯Î±', 'Î»Î¿Î³Î¹ÏƒÏ„Î¹Îº', 'Î¿Î¹ÎºÎ¿Î½Î¿Î¼Î¹Îº', 'Ï„ÏƒÎ¼ÎµÎ´Îµ', 'ÎµÏ†ÎºÎ±']):
        return "ğŸ’¼ Î¦Î¿ÏÎ¿Î»Î¿Î³Î¹ÎºÎ¬ & Î‘ÏƒÏ†Î±Î»Î¹ÏƒÏ„Î¹ÎºÎ¬"
    elif any(x in text for x in ['Î´Î¹Î±Î³Ï‰Î½Î¹ÏƒÎ¼', 'Î´Î·Î¼ÏŒÏƒÎ¹Î± Î­ÏÎ³Î±', 'Î¼ÎµÎ»Î­Ï„ÎµÏ‚', 'ÏƒÏÎ¼Î²Î±ÏƒÎ·', 'Î±Î½Î¬Î¸ÎµÏƒÎ·', 'ÎµÏƒÏ€Î±', 'Ï…Ï€Î¿Î´Î¿Î¼Î­Ï‚', 'Î¼ÎµÏ„ÏÏŒ', 'Î¿Î´Î¹ÎºÏŒÏ‚', 'Ï€ÎµÎ´Î¼ÎµÎ´Îµ', 'Î´Î¹Î±ÎºÎ®ÏÏ…Î¾Î·']):
        return "âœ’ï¸ Î”Î·Î¼ÏŒÏƒÎ¹Î± ÎˆÏÎ³Î± & Î•Î£Î Î‘"
    elif any(x in text for x in ['Ï„ÎµÎµ', 'Î¼Î·Ï‡Î±Î½Î¹Îº', 'ÎµÏ€Î¹Î¼ÎµÎ»Î·Ï„Î®ÏÎ¹Î¿', 'ÎµÎºÎ»Î¿Î³Î­Ï‚', 'Ï€ÎµÎ¹Î¸Î±ÏÏ‡Î¹Îº', 'ÏƒÎµÎ¼Î¹Î½Î¬ÏÎ¹', 'Î·Î¼ÎµÏÎ¯Î´Î±', 'ÏƒÏ…Î½Î­Î´ÏÎ¹Î¿']):
        return "ğŸ›ï¸ Î˜ÎµÏƒÎ¼Î¹ÎºÎ¬ Î¤Î•Î• & Î•Ï€Î¬Î³Î³ÎµÎ»Î¼Î±"
    else:
        return "ğŸ“¢ Î“ÎµÎ½Î¹ÎºÎ® Î•Î½Î·Î¼Î­ÏÏ‰ÏƒÎ·"

def run_bot_update_manual():
    sheet = get_db_connection()
    if not sheet: return 0
    
    try:
        existing_data = sheet.get_all_records()
        existing_links = [row['link'] for row in existing_data]
    except:
        existing_data = []
        existing_links = []
    
    new_items_found = 0
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    total_feeds = len(RSS_FEEDS)
    current_feed = 0
    
    for source, url in RSS_FEEDS.items():
        current_feed += 1
        progress = current_feed / total_feeds
        progress_bar.progress(progress)
        status_text.text(f"ğŸ“¡ Î£Î¬ÏÏ‰ÏƒÎ·: {source}...")
        
        try:
            feed = feedparser.parse(url)
            for entry in feed.entries[:3]: 
                if entry.link not in existing_links:
                    category = guess_category(entry.title + " " + entry.summary)
                    new_row = [
                        len(existing_data) + new_items_found + 1,
                        source,
                        entry.title,
                        entry.summary[:200] + "...",
                        entry.link,
                        datetime.now().strftime("%Y-%m-%d"),
                        category 
                    ]
                    sheet.append_row(new_row)
                    new_items_found += 1
                    existing_links.append(entry.link)
        except Exception:
            pass
            
    progress_bar.empty()
    status_text.empty()
    return new_items_found

# --- 4. NAVIGATION MENU ---
with st.sidebar:
    st.markdown("## ğŸ›ï¸ NomoTechi")
    st.caption("Intelligence for Engineers")
    st.markdown("---")
    
    selected_page = st.radio(
        "Î Î»Î¿Î®Î³Î·ÏƒÎ·:", 
        ["ğŸ“Š Dashboard", "ğŸ” Î‘Î½Î±Î¶Î®Ï„Î·ÏƒÎ· & Î‘ÏÏ‡ÎµÎ¯Î¿", "âš™ï¸ Î”Î¹Î±Ï‡ÎµÎ¯ÏÎ¹ÏƒÎ· (Admin)"],
        index=0
    )
    
    st.markdown("---")
    st.info("ğŸ’¡ Tip: Î— Î²Î¬ÏƒÎ· ÎµÎ½Î·Î¼ÎµÏÏÎ½ÎµÏ„Î±Î¹ Î±Ï…Ï„ÏŒÎ¼Î±Ï„Î± ÎºÎ¬Î¸Îµ Ï€ÏÏ‰Î¯ ÏƒÏ„Î¹Ï‚ 08:00.")

# --- LOAD DATA ---
data = load_data()
df = pd.DataFrame(data)

# --- PAGE 1: DASHBOARD ---
if selected_page == "ğŸ“Š Dashboard":
    st.markdown('<p class="main-header">NomoTechi Dashboard</p>', unsafe_allow_html=True)
    st.markdown('<p class="sub-header">Î— ÎºÎ±Î¸Î·Î¼ÎµÏÎ¹Î½Î® ÎµÎ½Î·Î¼Î­ÏÏ‰ÏƒÎ· Ï„Î¿Ï… ÎœÎ·Ï‡Î±Î½Î¹ÎºÎ¿Ï ÏƒÎµ Î¼Î¯Î± Î¿Î¸ÏŒÎ½Î·</p>', unsafe_allow_html=True)
    
    if not df.empty:
        # Metrics Row
        col1, col2, col3, col4 = st.columns(4)
        col1.metric("Î£ÏÎ½Î¿Î»Î¿ Î†ÏÎ¸ÏÏ‰Î½", len(df))
        col2.metric("Î Î·Î³Î­Ï‚ Î•Î½Î·Î¼Î­ÏÏ‰ÏƒÎ·Ï‚", len(RSS_FEEDS))
        
        # Î¥Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒÏ‚ ÏƒÎ·Î¼ÎµÏÎ¹Î½ÏÎ½ Î¬ÏÎ¸ÏÏ‰Î½
        today = datetime.now().strftime("%Y-%m-%d")
        today_articles = df[df['last_update'] == today].shape[0]
        col3.metric("Î£Î·Î¼ÎµÏÎ¹Î½Î¬ Î†ÏÎ¸ÏÎ±", today_articles, delta=today_articles)
        
        col4.metric("ÎšÎ±Ï„Î¬ÏƒÏ„Î±ÏƒÎ·", "Online ğŸŸ¢")
        
        st.markdown("---")
        st.subheader("ğŸ”¥ Î¤ÎµÎ»ÎµÏ…Ï„Î±Î¯ÎµÏ‚ Î•Î¹Î´Î®ÏƒÎµÎ¹Ï‚")
        
        # Show top 10 latest
        df_sorted = df.iloc[::-1].head(10)
        
        for index, row in df_sorted.iterrows():
            with st.container():
                c1, c2 = st.columns([0.85, 0.15])
                with c1:
                    st.markdown(f"**{row['title']}**")
                    st.caption(f"{row['last_update']} | {row['law']}")
                with c2:
                    st.markdown(f"*{row['category']}*")
                
                with st.expander("Î ÎµÏÎ¯Î»Î·ÏˆÎ·"):
                    st.write(row['content'])
                    st.markdown(f"ğŸ‘‰ [Î”Î¹Î±Î²Î¬ÏƒÏ„Îµ Ï„Î¿ Ï€Î»Î®ÏÎµÏ‚ Î¬ÏÎ¸ÏÎ¿]({row['link']})")
                st.divider()
    else:
        st.warning("Î— Î²Î¬ÏƒÎ· Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ ÎµÎ¯Î½Î±Î¹ ÎºÎµÎ½Î®. Î Î·Î³Î±Î¯Î½ÎµÏ„Îµ ÏƒÏ„Î¿ Î¼ÎµÎ½Î¿Ï Admin Î³Î¹Î± Î±ÏÏ‡Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ·.")

# --- PAGE 2: SEARCH & FILTER ---
elif selected_page == "ğŸ” Î‘Î½Î±Î¶Î®Ï„Î·ÏƒÎ· & Î‘ÏÏ‡ÎµÎ¯Î¿":
    st.header("ğŸ—‚ï¸ Î’Î¹Î²Î»Î¹Î¿Î¸Î®ÎºÎ· Î•Î¹Î´Î®ÏƒÎµÏ‰Î½")
    
    if not df.empty:
        # --- FILTERS SECTION ---
        with st.expander("ğŸ” Î¦Î¯Î»Ï„ÏÎ± Î‘Î½Î±Î¶Î®Ï„Î·ÏƒÎ·Ï‚", expanded=True):
            col_search, col_cat, col_source = st.columns([2, 1, 1])
            
            with col_search:
                search_term = st.text_input("Î‘Î½Î±Î¶Î®Ï„Î·ÏƒÎ· (Ï€.Ï‡. Î±Ï…Î¸Î±Î¯ÏÎµÏ„Î±, ÎµÎ¾Î¿Î¹ÎºÎ¿Î½Î¿Î¼Ï)...")
            
            with col_cat:
                categories = sorted(df['category'].unique().tolist()) if 'category' in df.columns else []
                selected_cats = st.multiselect("ÎšÎ±Ï„Î·Î³Î¿ÏÎ¯Î±", categories)
                
            with col_source:
                sources = sorted(df['law'].unique().tolist())
                selected_sources = st.multiselect("Î Î·Î³Î®", sources)
        
        # --- FILTERING LOGIC ---
        df_filtered = df.copy()
        
        # Filter by text
        if search_term:
            df_filtered = df_filtered[df_filtered['title'].str.contains(search_term, case=False) | df_filtered['content'].str.contains(search_term, case=False)]
            
        # Filter by category
        if selected_cats:
            df_filtered = df_filtered[df_filtered['category'].isin(selected_cats)]
            
        # Filter by source
        if selected_sources:
            df_filtered = df_filtered[df_filtered['law'].isin(selected_sources)]
            
        # Sort latest first
        df_filtered = df_filtered.iloc[::-1]
        
        st.markdown(f"**Î’ÏÎ­Î¸Î·ÎºÎ±Î½ {len(df_filtered)} Î±Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î±:**")
        st.divider()
        
        # --- DISPLAY RESULTS ---
        for index, row in df_filtered.iterrows():
            st.markdown(f"### {row['title']}")
            
            # Badge Line
            col_badges = st.columns([1, 1, 4])
            col_badges[0].markdown(f"ğŸ“… `{row['last_update']}`")
            col_badges[1].markdown(f"ğŸ·ï¸ `{row['category']}`")
            col_badges[2].markdown(f"ğŸ”— **{row['law']}**")
            
            st.write(row['content'])
            st.markdown(f"[Î”Î¹Î±Î²Î¬ÏƒÏ„Îµ Ï€ÎµÏÎ¹ÏƒÏƒÏŒÏ„ÎµÏÎ± ÏƒÏ„Î¿ {row['law']} â†—]({row['link']})")
            st.markdown("---")

    else:
        st.info("Î”ÎµÎ½ Ï…Ï€Î¬ÏÏ‡Î¿Ï…Î½ Î´ÎµÎ´Î¿Î¼Î­Î½Î±.")

# --- PAGE 3: ADMIN ---
elif selected_page == "âš™ï¸ Î”Î¹Î±Ï‡ÎµÎ¯ÏÎ¹ÏƒÎ· (Admin)":
    st.header("ğŸ” ÎšÎ­Î½Ï„ÏÎ¿ Î•Î»Î­Î³Ï‡Î¿Ï…")
    
    password = st.text_input("ÎšÏ‰Î´Î¹ÎºÏŒÏ‚ Î”Î¹Î±Ï‡ÎµÎ¹ÏÎ¹ÏƒÏ„Î®", type="password")
    
    if password == st.secrets.get("admin_password", ""):
        st.success("Î•Î¯ÏƒÎ¿Î´Î¿Ï‚ ÎµÏ€Î¹Ï„Ï…Ï‡Î®Ï‚")
        
        st.subheader("ğŸ› ï¸ Î•ÏÎ³Î±Î»ÎµÎ¯Î±")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("### ğŸ”„ Î§ÎµÎ¹ÏÎ¿ÎºÎ¯Î½Î·Ï„Î¿Ï‚ Î£Ï…Î³Ï‡ÏÎ¿Î½Î¹ÏƒÎ¼ÏŒÏ‚")
            st.write("Î£Î¬ÏÏ‰ÏƒÎ· ÎºÎ±Î¹ Ï„Ï‰Î½ 10 Ï€Î·Î³ÏÎ½ Ï„ÏÏÎ±.")
            if st.button("ğŸš€ ÎˆÎ½Î±ÏÎ¾Î· Î£Î¬ÏÏ‰ÏƒÎ·Ï‚", type="primary"):
                count = run_bot_update_manual()
                if count > 0:
                    st.success(f"Î’ÏÎ­Î¸Î·ÎºÎ±Î½ {count} Î½Î­Î± Î¬ÏÎ¸ÏÎ±!")
                    time.sleep(2)
                    st.rerun()
                else:
                    st.info("Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎ±Î½ Î½Î­Î± Î¬ÏÎ¸ÏÎ±.")
        
        with col2:
            st.markdown("### ğŸ—‘ï¸ ÎšÎ±Î¸Î±ÏÎ¹ÏƒÎ¼ÏŒÏ‚ Cache")
            st.write("Î‘Î½ ÎºÎ¿Î»Î»Î®ÏƒÎµÎ¹ Î· ÎµÏ†Î±ÏÎ¼Î¿Î³Î®.")
            if st.button("ğŸ§¹ Clear Cache"):
                st.cache_data.clear()
                st.rerun()
        
        st.divider()
        st.subheader("ğŸ“‹ Î ÏÎ¿Î²Î¿Î»Î® Î”ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ (Raw)")
        st.dataframe(df, use_container_width=True)
        
    elif password != "":
        st.error("Î›Î¬Î¸Î¿Ï‚ ÎºÏ‰Î´Î¹ÎºÏŒÏ‚.")
