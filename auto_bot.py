import os
import json
import gspread
import feedparser
from datetime import datetime
import re

# --- 1. ÎŸÎ™ Î Î—Î“Î•Î£ ---
RSS_FEEDS = {
    # ÎÎŸÎœÎŸÎ˜Î•Î£Î™Î‘ & Î”Î™ÎšÎ‘Î™ÎŸÎ£Î¥ÎÎ—
    "ğŸ“œ E-Nomothesia": "https://www.e-nomothesia.gr/rss.xml",
    "âš–ï¸ Î”Î£Î‘": "https://www.dsa.gr/rss.xml",
    "âš–ï¸ Lawspot": "https://www.lawspot.gr/nomika-nea/feed",
    "ğŸ“ Dikaiologitika": "https://www.dikaiologitika.gr/feed", 
    "ğŸ’¼ Taxheaven": "https://www.taxheaven.gr/rss",

    # Î¤Î•Î§ÎÎ™ÎšÎ‘ & Î Î•Î¡Î™Î’Î‘Î›Î›ÎŸÎÎ¤Î™ÎšÎ‘
    "ğŸ›ï¸ Î¤Î•Î•": "https://web.tee.gr/feed/",
    "ğŸ—ï¸ Ypodomes": "https://ypodomes.com/feed/",
    "ğŸŒ¿ B2Green": "https://news.b2green.gr/feed",
    "âš¡ EnergyPress": "https://energypress.gr/feed",
    "ğŸšœ PEDMEDE": "https://www.pedmede.gr/feed/",
    "ğŸ‘· Michanikos": "https://www.michanikos-online.gr/feed/",
    "ğŸŒ GreenAgenda": "https://greenagenda.gr/feed/",
    
    # Î‘ÎšÎ™ÎÎ—Î¤Î‘ & ÎŸÎ™ÎšÎŸÎÎŸÎœÎ™Î‘
    "ğŸ  POMIDA": "https://www.pomida.gr/feed/",
    "ğŸ“ Archetypes": "https://www.archetypes.gr/feed/",
    "ğŸ’° Capital": "https://www.capital.gr/rss/oikonomia"
}

# --- 2. ADVANCED AI CLASSIFIER ---
def remove_accents(input_str):
    """Î’Î¿Î·Î¸Î·Ï„Î¹ÎºÎ® ÏƒÏ…Î½Î¬ÏÏ„Î·ÏƒÎ· Î³Î¹Î± Î½Î± ÎºÎ±Î¸Î±ÏÎ¯Î¶ÎµÎ¹ Ï„ÏŒÎ½Î¿Ï…Ï‚ (Ï€.Ï‡. Î¬Î´ÎµÎ¹Î± -> Î±Î´ÎµÎ¹Î±)"""
    replacements = {
        'Î¬': 'Î±', 'Î­': 'Îµ', 'Î®': 'Î·', 'Î¯': 'Î¹', 'ÏŒ': 'Î¿', 'Ï': 'Ï…', 'Ï': 'Ï‰',
        'Î†': 'Î‘', 'Îˆ': 'Î•', 'Î‰': 'Î—', 'ÎŠ': 'Î™', 'ÎŒ': 'ÎŸ', 'Î': 'Î¥', 'Î': 'Î©',
        'ÏŠ': 'Î¹', 'Ï‹': 'Ï…', 'Î': 'Î¹', 'Î°': 'Ï…'
    }
    for char, replacement in replacements.items():
        input_str = input_str.replace(char, replacement)
    return input_str.lower()

def guess_category_smart(title, summary, source_name):
    # Î•Î½Ï‰ÏƒÎ· ÎºÎµÎ¹Î¼Î­Î½Î¿Ï… ÎºÎ±Î¹ ÎºÎ±Î¸Î±ÏÎ¹ÏƒÎ¼ÏŒÏ‚
    full_text = remove_accents(title + " " + summary)
    source_clean = remove_accents(source_name)

    # --- Î’Î—ÎœÎ‘ 1: HARD RULES Î’Î‘Î£Î•Î™ Î Î—Î“Î—Î£ (Source Weighting) ---
    # ÎšÎ¬Ï€Î¿Î¹ÎµÏ‚ Ï€Î·Î³Î­Ï‚ ÎµÎ¯Î½Î±Î¹ Î¼Î¿Î½Î¿Î¸ÎµÎ¼Î±Ï„Î¹ÎºÎ­Ï‚. Î¤Î¹Ï‚ ÎµÎ¼Ï€Î¹ÏƒÏ„ÎµÏ…ÏŒÎ¼Î±ÏƒÏ„Îµ.
    if "e-nomothesia" in source_clean:
        return "ğŸ“œ ÎÎ¿Î¼Î¿Î¸ÎµÏƒÎ¯Î± & Î¦Î•Îš"
    if "greenagenda" in source_clean or "b2green" in source_clean:
        # Î•Î¾Î±Î¯ÏÎµÏƒÎ·: Î‘Î½ Î¼Î¹Î»Î¬ÎµÎ¹ Î³Î¹Î± Î½ÏŒÎ¼Î¿, Ï€Î¬ÎµÎ¹ Î½Î¿Î¼Î¿Î¸ÎµÏƒÎ¯Î±, Î±Î»Î»Î¹ÏÏ‚ Ï€ÎµÏÎ¹Î²Î¬Î»Î»Î¿Î½
        if any(w in full_text for w in ['Ï†ÎµÎº', 'Ï„ÏÎ¿Ï€Î¿Î»Î¿Î³Î¹Î±', 'Î½Î¿Î¼Î¿ÏƒÏ‡ÎµÎ´Î¹Î¿']):
            return "ğŸ“œ ÎÎ¿Î¼Î¿Î¸ÎµÏƒÎ¯Î± & Î¦Î•Îš"
        return "ğŸŒ± ÎœÎ·Ï‡Î±Î½Î¹ÎºÎ¿Î¯: Î•Î½Î­ÏÎ³ÎµÎ¹Î± & Î ÎµÏÎ¹Î²Î¬Î»Î»Î¿Î½"
    if "energypress" in source_clean:
        return "ğŸŒ± ÎœÎ·Ï‡Î±Î½Î¹ÎºÎ¿Î¯: Î•Î½Î­ÏÎ³ÎµÎ¹Î± & Î ÎµÏÎ¹Î²Î¬Î»Î»Î¿Î½"
    if "pomida" in source_clean:
        return "ğŸ–‹ï¸ Î£Ï…Î¼Î²Î¿Î»Î±Î¹Î¿Î³ÏÎ±Ï†Î¹ÎºÎ¬ & Î‘ÎºÎ¯Î½Î·Ï„Î±"

    # --- Î’Î—ÎœÎ‘ 2: Î‘Î¡ÎÎ—Î¤Î™ÎšÎ‘ Î¦Î™Î›Î¤Î¡Î‘ (SAFETY NET) ---
    # Î›Î­Î¾ÎµÎ¹Ï‚ Ï€Î¿Ï… Î´ÎµÎ¯Ï‡Î½Î¿Ï…Î½ Ï†Ï…ÏƒÎ¹ÎºÎ® ÎºÎ±Ï„Î±ÏƒÏ„ÏÎ¿Ï†Î® Î® Î³ÎµÎ½Î¹ÎºÎ¬ Î½Î­Î± (Î“Î™Î‘ ÎÎ‘ ÎœÎ—Î ÎœÎ Î‘Î™ÎÎŸÎ¥Î Î£Î¤Î‘ ÎÎŸÎœÎ™ÎšÎ‘)
    nature_words = ['Î·Ï†Î±Î¹ÏƒÏ„ÎµÎ¹Î¿', 'ÏƒÎµÎ¹ÏƒÎ¼Î¿Ï‚', 'Ï‡Î¹Î¿Î½Î¹Î±', 'ÎºÎ±ÎºÎ¿ÎºÎ±Î¹ÏÎ¹Î±', 'Ï€Ï…ÏÎºÎ±Î³Î¹Î±', 'Ï†Ï‰Ï„Î¹Î±', 'Ï€Î»Î·Î¼Î¼Ï…ÏÎ±', 'ÎºÎ±Î¹ÏÎ¿Ï‚', 'Î´ÎµÎ»Ï„Î¹Î¿ Ï„Ï…Ï€Î¿Ï…', 'ÎµÎºÎ´Î·Î»Ï‰ÏƒÎ·', 'ÏƒÏ…Î½ÎµÎ´ÏÎ¹Î¿']
    is_nature_event = any(w in full_text for w in nature_words)

    # --- Î’Î—ÎœÎ‘ 3: Î›Î•ÎÎ•Î™Î£ ÎšÎ›Î•Î™Î”Î™Î‘ ÎœÎ• Î Î¡ÎŸÎ¤Î•Î¡Î‘Î™ÎŸÎ¤Î—Î¤Î‘ ---

    # 1. ÎÎŸÎœÎŸÎ˜Î•Î£Î™Î‘ (Î‘Ï€ÏŒÎ»Ï…Ï„Î· Î ÏÎ¿Ï„ÎµÏÎ±Î¹ÏŒÏ„Î·Ï„Î±)
    if any(w in full_text for w in ['Ï†ÎµÎº', 'ÎµÎ³ÎºÏ…ÎºÎ»Î¹Î¿Ï‚', 'ÎºÏ…Î±', 'Ï€ÏÎ¿ÎµÎ´riko Î´Î¹Î±Ï„Î±Î³Î¼Î±', 'Î½Î¿Î¼Î¿ÏƒÏ‡ÎµÎ´Î¹Î¿', 'ÏˆÎ·Ï†Î¹ÏƒÏ„Î·ÎºÎµ', 'Ï„ÏÎ¿Ï€Î¿Î»Î¿Î³Î¹Î±']):
        return "ğŸ“œ ÎÎ¿Î¼Î¿Î¸ÎµÏƒÎ¯Î± & Î¦Î•Îš"

    # 2. ÎœÎ—Î§Î‘ÎÎ™ÎšÎŸÎ™ - Î ÎŸÎ›Î•ÎŸÎ”ÎŸÎœÎ™Î‘
    eng_keywords = ['Î±Ï…Î¸Î±Î¹ÏÎµÏ„Î±', '4495', 'Ï€Î¿Î»ÎµÎ¿Î´Î¿Î¼', 'Î´Î¿Î¼Î·ÏƒÎ·', 'ÎºÏ„Î¹ÏÎ¹Î¿Î´Î¿Î¼', 'Î±Î´ÎµÎ¹ÎµÏ‚', 'Î¿Î¹ÎºÎ¿Î´Î¿Î¼', 'Î½Î¿Îº', 'Ï„Î¿Ï€Î¿Î³ÏÎ±Ï†Î¹Îº', 'Ï„Î±Ï…Ï„Î¿Ï„Î·Ï„Î± ÎºÏ„Î¹ÏÎ¹Î¿Ï…', 'ÎºÏ„Î·Î¼Î±Ï„Î¿Î»Î¿Î³Î¹Î¿', 'Î´Î±ÏƒÎ¹Îº']
    if any(w in full_text for w in eng_keywords):
        return "ğŸ“ ÎœÎ·Ï‡Î±Î½Î¹ÎºÎ¿Î¯: Î Î¿Î»ÎµÎ¿Î´Î¿Î¼Î¯Î±"

    # 3. ÎœÎ—Î§Î‘ÎÎ™ÎšÎŸÎ™ - Î•Î¡Î“Î‘
    erga_keywords = ['Î´Î¹Î±Î³Ï‰Î½Î¹ÏƒÎ¼', 'Î´Î·Î¼Î¿ÏƒÎ¹Î± ÎµÏÎ³Î±', 'Î±Î½Î±Î¸ÎµÏƒÎ·', 'ÏƒÏ…Î¼Î²Î±ÏƒÎ·', 'Ï…Ï€Î¿Î´Î¿Î¼ÎµÏ‚', 'Î¼ÎµÏ„ÏÎ¿', 'Î¿Î´Î¹ÎºÎ¿Ï‚', 'Ï€ÎµÎ´Î¼ÎµÎ´Îµ', 'Î¼ÎµÎ¹Î¿Î´Î¿Ï„']
    if any(w in full_text for w in erga_keywords):
        return "âœ’ï¸ ÎœÎ·Ï‡Î±Î½Î¹ÎºÎ¿Î¯: ÎˆÏÎ³Î±"

    # 4. Î•ÎÎ•Î¡Î“Î•Î™Î‘ (Î‘Î½ Î´ÎµÎ½ Ï„Î¿ Î­Ï€Î¹Î±ÏƒÎµ Ï„Î¿ Source Rule)
    energy_keywords = ['ÎµÎ¾Î¿Î¹ÎºÎ¿Î½Î¿Î¼Ï‰', 'Ï†Ï‰Ï„Î¿Î²Î¿Î»Ï„Î±Î¹Îº', 'ÎµÎ½ÎµÏÎ³ÎµÎ¹Î±', 'Î±Ï€Îµ', 'ÏÎ±Îµ', 'Ï…Î´ÏÎ¿Î³Î¿Î½Î¿', 'ÎºÎ»Î¹Î¼Î±Ï„Î¹Îº', 'Ï€ÎµÏÎ¹Î²Î±Î»Î»Î¿Î½', 'Î±Î½Î±ÎºÏ…ÎºÎ»Ï‰ÏƒÎ·']
    if any(w in full_text for w in energy_keywords):
        return "ğŸŒ± ÎœÎ·Ï‡Î±Î½Î¹ÎºÎ¿Î¯: Î•Î½Î­ÏÎ³ÎµÎ¹Î± & Î ÎµÏÎ¹Î²Î¬Î»Î»Î¿Î½"

    # 5. Î£Î¥ÎœÎ’ÎŸÎ›Î‘Î™ÎŸÎ“Î¡Î‘Î¦Î™ÎšÎ‘ & Î‘ÎšÎ™ÎÎ—Î¤Î‘
    prop_keywords = ['ÏƒÏ…Î¼Î²Î¿Î»Î±Î¹Î¿Î³ÏÎ±Ï†', 'Î¼ÎµÏ„Î±Î²Î¹Î²Î±ÏƒÎ·', 'Î³Î¿Î½Î¹ÎºÎ· Ï€Î±ÏÎ¿Ï‡Î·', 'ÎºÎ»Î·ÏÎ¿Î½Î¿Î¼Î¹', 'Î´Î¹Î±Î¸Î·ÎºÎ·', 'Î±Î½Ï„Î¹ÎºÎµÎ¹Î¼ÎµÎ½Î¹Îº', 'enfia', 'Ï…Ï€Î¿Î¸Î·ÎºÎ¿Ï†Ï…Î»Î±Îº', 'Îµ9']
    if any(w in full_text for w in prop_keywords):
        return "ğŸ–‹ï¸ Î£Ï…Î¼Î²Î¿Î»Î±Î¹Î¿Î³ÏÎ±Ï†Î¹ÎºÎ¬ & Î‘ÎºÎ¯Î½Î·Ï„Î±"

    # 6. ÎÎŸÎœÎ™ÎšÎ‘ (Î Î¡ÎŸÎ£ÎŸÎ§Î—: Î•Î´Ï Î³Î¹Î½ÏŒÏ„Î±Î½ Ï„Î¿ Î»Î¬Î¸Î¿Ï‚ Î¼Îµ Ï„Î¿ Î·Ï†Î±Î¯ÏƒÏ„ÎµÎ¹Î¿)
    # Î¤ÏÏÎ± Î¼Ï€Î±Î¯Î½ÎµÎ¹ ÎœÎŸÎÎŸ Î±Î½ Î´ÎµÎ½ ÎµÎ¯Î½Î±Î¹ Ï†Ï…ÏƒÎ¹ÎºÎ® ÎºÎ±Ï„Î±ÏƒÏ„ÏÎ¿Ï†Î®, Î® Î±Î½ Î­Ï‡ÎµÎ¹ Ï€Î¿Î»Ï Î¹ÏƒÏ‡Ï…ÏÎ¿ÏÏ‚ Î½Î¿Î¼Î¹ÎºÎ¿ÏÏ‚ ÏŒÏÎ¿Ï…Ï‚
    legal_keywords = ['Î´Î¹ÎºÎ±ÏƒÏ„Î·ÏÎ¹', 'Î±ÏÎµÎ¿Ï€Î±Î³', 'ÏƒÏ„Îµ', 'Ï€Î¿Î¹Î½Î¹Îº', 'Î±ÏƒÏ„Î¹Îº', 'Î´Î¹ÎºÎ·', 'Î±Î³Ï‰Î³Î·', 'Î´Î¹ÎºÎ·Î³Î¿Ï', 'Î¿Î»Î¿Î¼ÎµÎ»ÎµÎ¹Î±', 'Ï€Î±ÏÎ±Î²Î±ÏƒÎ·', 'ÎºÎ±Ï„Î·Î³Î¿ÏÎ¿Ï…Î¼ÎµÎ½']
    strong_legal = ['Î±ÏÎµÎ¿Ï€Î±Î³', 'ÏƒÏ„Îµ', 'ÎµÏ†ÎµÏ„ÎµÎ¹Î¿', 'Î´Î¹ÎºÎ±ÏƒÏ„Î¹ÎºÎ· Î±Ï€Î¿Ï†Î±ÏƒÎ·'] # Î‘Ï…Ï„Î¬ ÎºÎµÏÎ´Î¯Î¶Î¿Ï…Î½ Î±ÎºÏŒÎ¼Î± ÎºÎ±Î¹ Ï„Î¿ Î·Ï†Î±Î¯ÏƒÏ„ÎµÎ¹Î¿
    
    has_legal_word = any(w in full_text for w in legal_keywords)
    has_strong_legal = any(w in full_text for w in strong_legal)

    if has_strong_legal: 
        return "âš–ï¸ ÎÎ¿Î¼Î¹ÎºÎ¬ Î˜Î­Î¼Î±Ï„Î±"
    if has_legal_word and not is_nature_event: 
        return "âš–ï¸ ÎÎ¿Î¼Î¹ÎºÎ¬ Î˜Î­Î¼Î±Ï„Î±"

    # 7. ÎŸÎ™ÎšÎŸÎÎŸÎœÎ™ÎšÎ‘ / Î¦ÎŸÎ¡ÎŸÎ›ÎŸÎ“Î™ÎšÎ‘
    if any(w in full_text for w in ['Ï†Î¿ÏÎ¿Î»Î¿Î³', 'Î±Î±Î´Îµ', 'mydata', 'ÎµÏ†Î¿ÏÎ¹Î±', 'Ï†Ï€Î±', 'Î¼Î¹ÏƒÎ¸Î¿Î´Î¿ÏƒÎ¹Î±', 'Ï„ÏÎ±Ï€ÎµÎ¶', 'Î´Î±Î½ÎµÎ¹', 'ÎµÏ†ÎºÎ±', 'ÏƒÏ…Î½Ï„Î±Î¾']):
        return "ğŸ’¼ Î¦Î¿ÏÎ¿Î»Î¿Î³Î¹ÎºÎ¬ & ÎŸÎ¹ÎºÎ¿Î½Î¿Î¼Î¯Î±"

    # 8. Î˜Î•Î£ÎœÎ™ÎšÎ‘
    if any(w in full_text for w in ['ÎµÎºÎ»Î¿Î³ÎµÏ‚', 'ÏˆÎ·Ï†Î¿Ï†Î¿ÏÎ¹Î±', 'Ï€Î±ÏÎ±Ï„Î±ÏƒÎ·', 'Î±Î½Î±ÎºÎ¿Î¹Î½Ï‰ÏƒÎ·']):
        return "ğŸ“¢ Î˜ÎµÏƒÎ¼Î¹ÎºÎ¬ & Î‘Î½Î±ÎºÎ¿Î¹Î½ÏÏƒÎµÎ¹Ï‚"

    # DEFAULT (Î‘Î½ ÎµÎ¯Î½Î±Î¹ Î·Ï†Î±Î¯ÏƒÏ„ÎµÎ¹Î¿ ÎºÎ±Î¹ Î´ÎµÎ½ Ï„Î±Î¯ÏÎ¹Î±Î¾Îµ Ï€Î¿Ï…Î¸ÎµÎ½Î¬ Î±Î»Î»Î¿Ï)
    return "ğŸŒ Î“ÎµÎ½Î¹ÎºÎ® Î•Î½Î·Î¼Î­ÏÏ‰ÏƒÎ·"

# --- 3. Î— ÎœÎ—Î§Î‘ÎÎ— Î¤ÎŸÎ¥ Î¡ÎŸÎœÎ ÎŸÎ¤ ---
def run():
    print(f"ğŸ¤– [NomoTechi AI] Î£Î¬ÏÏ‰ÏƒÎ· ÎºÎ±Î¹ ÎšÎ±Ï„Î·Î³Î¿ÏÎ¹Î¿Ï€Î¿Î¯Î·ÏƒÎ· Î¾ÎµÎºÎ¯Î½Î·ÏƒÎµ...")
    
    json_creds = os.environ.get("GCP_CREDENTIALS")
    if not json_creds: return

    try:
        creds_dict = json.loads(json_creds)
        gc = gspread.service_account_from_dict(creds_dict)
        sh = gc.open("laws_database")
        sheet = sh.sheet1
    except Exception as e:
        print(f"Connection Error: {e}")
        return

    try:
        existing_data = sheet.get_all_records()
        existing_links = [row['link'] for row in existing_data]
    except:
        existing_data = []
        existing_links = []
        
    new_items_count = 0
    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)'}

    for source_name, url in RSS_FEEDS.items():
        try:
            feed = feedparser.parse(url, agent=headers['User-Agent'])
            if not feed.entries and feed.bozo: continue
                
            for entry in feed.entries[:5]: 
                if entry.link not in existing_links:
                    
                    title = entry.title
                    summary = entry.summary.replace("<p>", "").replace("</p>", "")[:250] + "..." if 'summary' in entry else ""
                    
                    # ÎšÎ‘Î›ÎŸÎ¥ÎœÎ• Î¤ÎŸÎ Î•ÎÎ¥Î ÎÎŸ CLASSIFIER ÎœÎ• Î¤ÎŸ ÎŸÎÎŸÎœÎ‘ Î¤Î—Î£ Î Î—Î“Î—Î£
                    category = guess_category_smart(title, summary, source_name)
                    
                    new_row = [
                        len(existing_data) + new_items_count + 1,
                        source_name,
                        title,
                        summary,
                        entry.link,
                        datetime.now().strftime("%Y-%m-%d"),
                        category
                    ]
                    
                    sheet.append_row(new_row)
                    new_items_count += 1
                    existing_links.append(entry.link)
                    print(f"   âœ… [{category}] {title[:30]}...")
                    
        except Exception:
            pass

    print(f"ğŸ ÎŸÎ»Î¿ÎºÎ»Î·ÏÏÎ¸Î·ÎºÎµ. ÎÎ­Î± Î¬ÏÎ¸ÏÎ±: {new_items_count}")

if __name__ == "__main__":
    run()
